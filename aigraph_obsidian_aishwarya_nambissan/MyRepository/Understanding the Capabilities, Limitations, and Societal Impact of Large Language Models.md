https://doi.org/10.48550/arXiv.2102.02503

By scaling model and training data size, [[Large Language Models|LLMs]]  can expand their abilities from zero-shot generalization to downstream tasks, to learn more novel tasks when given examples in context.

Large multimodal models will become more prevalent and enable more diverse capabilities. That is, models trained on different types of data, including images and audio recordings. The main benefit of multimodal training might be to improve the speed at which models acquire useful capabilities, as the interaction between different data modalities may provide a stronger learning signal than each data modality in isolation provides.

GPT-3 has an unusually large set of capabilities, including text summarization, chatbot behavior, search, code generation, and essay generation. Such a large “capability surface” makes it challenging to both scope the full array of uses and to ensure
their safety to people and societies.

Possible means of addressing harmful biases in language models:
• Changes to the initial training data to mitigate bias a priori
• Training a separate model to filter content generated by a language model
• Fine-tuning a large language model on data with desired properties
• Tagging data so that the model learns to distinguish among certain forms of content
• Training models to be more “fact-aware”
• Reinforcement learning with human feedback
• Leveraging the model’s own knowledge to improve outputs (e.g., with careful prompt design)
• Developing more expansive suites of “bias tests” that models can be run through prior to deployment
•Interrogating the model for potential misuse and develop mitigation strategies at scale by engaging trusted partners to work with the model and through limited commercial offerings.



