[[2212.09689] Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor (arxiv.org)](https://arxiv.org/abs/2212.09689)

#fine-tune 

Instruction tuning: 
It is a technique that enables pretrained language models to perform new tasks from inference-time natural language descriptions. It involves fine-tuning the language model on a dataset of instructions and their execution, which allows the model to generalize to unseen tasks in a zero-shot setting. This approach relies on vast amounts of human supervision in the form of crowdsourced datasets or user interactions.

The Unnatural Instructions dataset:
The dataset was collected in a completely automatic process, requiring a seed of only 15 manually-constructed examples.

Advantages of Unnatural Instructions:
1. Cost-effectiveness.
2. Scalability.
3. Creativity and Diversity.