
[https://doi.org/10.48550/arXiv.2308.16688](https://doi.org/10.48550/arXiv.2308.16688)

[[Large Language Models]]

Conventionally, it is assumed that for [[Text Classification|text classification]], there is a fixed set of predefined labels. But, in real life scenarios, the label space for describing a text is unlimited. To address this issue, _Zero shot learning_ is used which involves classifying instances into categories without any labelled training data. Semantic embeddings and textual descriptors are used to bridge the gap between known and unknown categories.

#### BART - Bidirectional and Auto-Regressive Transformers 

A neural network model that is a mix of bi-directional encoder found in BERT and the autoregressive decoder used in GPT having 140-400 million parameters. the BART is open source and can be executed on CPU, offering both good performance and accessibility to a wider user base.

Technology trend analysis - to see the frequencies of publication of research across different classes to gain insight about areas that require future investigation and resource allocation for the same.

Interest trend analysis -  to identify popular techniques or topics over a period of time which facilitates the detection of emerging trends and evaluation of long term patterns.


For the classification of ophthalmology related articles, BART receives the title and abstract as input to generate probabilities for different categories and the final label for the multiclass classification of the articles are obtained by taking the maximum probability amongst all the classes. This BART ZSL framework demonstrated promising results in categorization and trend analysis, showing the proliferation of machine learning and technology related articles in the field of ophthalmology. This study has led to the categorization of ophthalmology articles which will allow for researches to access relevant studies quickly. 





